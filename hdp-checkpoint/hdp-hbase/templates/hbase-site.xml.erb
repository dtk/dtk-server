<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://<%=scope.function_hdp_host("namenode_host")%>:8020<%=scope.function_hdp_template_var("hbase_hdfs_root_dir")%></value>
    <description>The directory shared by region servers and into
    which HBase persists.  The URL should be 'fully-qualified'
    to include the filesystem scheme.  For example, to specify the
    HDFS directory '/hbase' where the HDFS instance's namenode is
    running at namenode.example.org on port 9000, set this value to:
    hdfs://namenode.example.org:9000/hbase.  By default HBase writes
    into /tmp.  Change this configuration else all data will be lost
    on machine restart.
    </description>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
    <description>The mode the cluster will be in. Possible values are
      false for standalone mode and true for distributed mode.  If
      false, startup will run all HBase and ZooKeeper daemons together
      in the one JVM.
    </description>
  </property>
  <property>
    <name>hbase.tmp.dir</name>
    <value><%=scope.function_hdp_template_var("hbase_tmp_dir")%></value>
    <description>Temporary directory on the local filesystem.
    Change this setting to point to a location more permanent
    than '/tmp' (The '/tmp' directory is often cleared on
    machine restart).
    </description>
  </property>
  <property>
    <name>hbase.master.info.bindAddress</name>
    <value><%=scope.function_hdp_host("hbase_master_host")%></value>
    <description>The bind address for the HBase Master web UI
    </description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.upperLimit</name>
    <value><%=scope.function_hdp_template_var("regionserver_memstore_upperlimit")%></value>
    <description>Maximum size of all memstores in a region server before new
      updates are blocked and flushes are forced. Defaults to 40% of heap
    </description>
  </property>
  <property>
    <name>hbase.regionserver.global.memstore.lowerLimit</name>
    <value><%=scope.function_hdp_template_var("regionserver_memstore_lowerlimit")%></value>
    <description>When memstores are being forced to flush to make room in
      memory, keep flushing until we hit this mark. Defaults to 35% of heap.
      This value equal to hbase.regionserver.global.memstore.upperLimit causes
      the minimum possible flushing to occur when updates are blocked due to
      memstore limiting.
    </description>
  </property>
  <property>
    <name>hbase.hregion.memstore.mslab.enabled</name>
    <value><%=scope.function_hdp_template_var("regionserver_memstore_lab")%></value>
    <description>
      Enables the MemStore-Local Allocation Buffer,
      a feature which works to prevent heap fragmentation under
      heavy write loads. This can reduce the frequency of stop-the-world
      GC pauses on large heaps.
    </description>
  </property>
  <property>
    <name>hbase.hregion.max.filesize</name>
    <value><%=scope.function_hdp_template_var("hstorefile_maxsize")%></value>
    <description>
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.
    Default: 1G.
    </description>
  </property>
  <property>
    <name>hbase.hstore.compactionThreshold</name>
    <value><%=scope.function_hdp_template_var("hstore_compactionthreshold")%></value>
    <description>
    If more than this number of HStoreFiles in any one HStore
    (one HStoreFile is written per flush of memstore) then a compaction
    is run to rewrite all HStoreFiles files as one.  Larger numbers
    put off compaction but when it runs, it takes longer to complete.
    </description>
  </property>
  <property>
    <name>hbase.hstore.blockingStoreFiles</name>
    <value><%=scope.function_hdp_template_var("hstore_blockingstorefiles")%></value>
    <description>
    If more than this number of StoreFiles in any one Store
    (one StoreFile is written per flush of MemStore) then updates are
    blocked for this HRegion until a compaction is completed, or
    until hbase.hstore.blockingWaitTime has been exceeded.
    </description>
  </property>
  <property>
    <name>hfile.block.cache.size</name>
    <value><%=scope.function_hdp_template_var("hfile_blockcache_size")%></value>
    <description>
        Percentage of maximum heap (-Xmx setting) to allocate to block cache
        used by HFile/StoreFile. Default of 0.25 means allocate 25%.
        Set to 0 to disable but it's not recommended.
    </description>
  </property>

  <!-- The following properties configure authentication information for
       HBase processes when using Kerberos security.  There are no default
       values, included here for documentation purposes -->
  <property>
    <name>hbase.master.keytab.file</name>
    <value><%=scope.function_hdp_template_var("keytab_path")%>/hm.service.keytab</value>
    <description>Full path to the kerberos keytab file to use for logging in
    the configured HMaster server principal.
    </description>
  </property>
  <property>
    <name>hbase.master.kerberos.principal</name>
    <value>hm/_HOST@<%=scope.function_hdp_template_var("kerberos_domain")%></value>
    <description>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HMaster process.  The principal name should
    be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the hostname
    portion, it will be replaced with the actual hostname of the running
    instance.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.keytab.file</name>
    <value><%=scope.function_hdp_template_var("keytab_path")%>/rs.service.keytab</value>
    <description>Full path to the kerberos keytab file to use for logging in
    the configured HRegionServer server principal.
    </description>
  </property>
  <property>
    <name>hbase.regionserver.kerberos.principal</name>
    <value>rs/_HOST@<%=scope.function_hdp_template_var("kerberos_domain")%></value>
    <description>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HRegionServer process.  The principal name
    should be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the
    hostname portion, it will be replaced with the actual hostname of the
    running instance.  An entry for this principal must exist in the file
    specified in hbase.regionserver.keytab.file
    </description>
  </property>

  <!-- Additional configuration specific to HBase security -->
  <property>
    <name>hbase.superuser</name>
    <value>hbase</value>
    <description>List of users or groups (comma-separated), who are allowed
    full privileges, regardless of stored ACLs, across the cluster.
    Only used when HBase security is enabled.
    </description>
  </property>

  <property>
    <name>hbase.coprocessor.region.classes</name>
    <value><%=scope.function_hdp_template_var("preloaded_regioncoprocessor_classes")%></value>
    <description>A comma-separated list of Coprocessors that are loaded by
    default on all tables. For any override coprocessor method, these classes
    will be called in order. After implementing your own Coprocessor, just put
    it in HBase's classpath and add the fully qualified class name here.
    A coprocessor can also be loaded on demand by setting HTableDescriptor.
    </description>
  </property>

  <property>
    <name>hbase.coprocessor.master.classes</name>
    <value><%=scope.function_hdp_template_var("preloaded_mastercoprocessor_classes")%></value>
    <description>A comma-separated list of
    org.apache.hadoop.hbase.coprocessor.MasterObserver coprocessors that are
    loaded by default on the active HMaster process. For any implemented
    coprocessor methods, the listed classes will be called in order. After
    implementing your own MasterObserver, just put it in HBase's classpath
    and add the fully qualified class name here.
    </description>
  </property>

  <!--
  The following three properties are used together to create the list of
  host:peer_port:leader_port quorum servers for ZooKeeper.
  -->
  <property>
    <name>hbase.zookeeper.quorum</name>
    <value><%=zkh=scope.function_hdp_host("zookeeper_hosts");(zkh.nil? or zkh.empty?) ? scope.function_hdp_template_var("::hdp::params::host_address") : [zkh].flatten(1).join(",")%></value>
    <description>Comma separated list of servers in the ZooKeeper Quorum.
    For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".
    By default this is set to localhost for local and pseudo-distributed modes
    of operation. For a fully-distributed setup, this should be set to a full
    list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
    this is the list of servers which we will start/stop ZooKeeper on.
    </description>
  </property>
  <!-- End of properties used to generate ZooKeeper host:port quorum list. -->

  <property>
    <name>dfs.support.append</name>
    <value><%=scope.function_hdp_template_var("hdfs_support_append")%></value>
    <description>Does HDFS allow appends to files?
    This is an hdfs config. set in here so the hdfs client will do append support.
    You must ensure that this config. is true serverside too when running hbase
    (You will have to restart your cluster after setting it).
    </description>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value><%=scope.function_hdp_template_var("hdfs_enable_shortcircuit_read")%></value>
    <description>Enable/Disable short circuit read for your client.
    Hadoop servers should be configured to allow short circuit read
    for the hbase user for this to take effect
    </description>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value><%=scope.function_hdp_template_var("hdfs_enable_shortcircuit_skipchecksum")%></value>
    <description>Enable/disbale skipping the checksum check</description>
  </property>
</configuration>
